<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>teachable machine</title>
	<link rel="stylesheet" href="style.css">
	
<link rel="stylesheet" href="favicon.ico">


</head>
<body>
	<header>
		<a href="index.html" class="left-link">zurück</a>
		<h1>Teachable Machine</h1>
	</header>
	<main>
      
				<p>Im Rahmen des Projekts zu "Googles Teachable Machine" wurde die Funktionsweise 
					sowie der Einsatz dieses Werkzeuges durch die Durchführung eines eigenständig gewählten Projekts erlernt.
				</p>
 
	<h4>Definition </h4>
	<p>
	Googles Teachable Machine ist ein webbasiertes Werkzeug, 
	mit dessen Hilfe sich Modelle für maschinelles Lernen erstellen lassen. 
	Es ist einfach zu bedienen und benötigt keine Programmierkenntnisse. 
	Teachable Machine kann Dateien oder live Beispiele von Bildern, Posen und Tönen verwenden. 
	In diesem Beispiel wird ein Modell für die Klassifizierung von Bildern erstellt.
</p>
<h4> Funktionsweise</h4>
<p>
	Das funktioniert indem das Modell trainiert wird, dafür werden Beispiele in mehrere Klassen unterteilt, 
	das Modell erkennt dann Unterschiede und Gemeinsamkeiten. Nach dem sichergestellt ist, dass auch Bilder die nicht zu den Datensätzen zählen,
	richtig zugeordnet werden, kann das Modell dabei helfen, unbekannte Dateien zu kategorisieren.
	</p>

<h6>Das Projekt</h6>
	

	
<h4>Die Idee</h4>
<p>
Der Unterschied zwischen hyperrealistischer Zeichnung und einem Foto ist manchmal kaum zu unterscheiden. 
Genau diese Grenze ist Interessant, die Bilder bei denen ganz genau geschaut werden muss, um zu erkennen ob es eine Zeichnung ist.
Kann eine Maschine diesen Unterschied besser erkennen als das menschliche Auge?
</p>
<h4>Vorgehensweise</h4>
<p>Nach einer eingehenden Recherche wurden mehr als 30 Bilder aus den Kategorien „Fotos“ und „Zeichnungen“ gesammelt, 
	die hinsichtlich ihres fotorealistischen Charakters variierten. 
	Die Teachable Machine wurde anschließend mit jeweils 20 Bildern pro Kategorie trainiert, 
	wobei eine Unterteilung in die Klassen „Fotos“ und „Zeichnungen“ vorgenommen wurde. 
	Im Anschluss wurde das Modell mit neuen Fotos getestet, die nicht Teil der Trainingsdaten waren, 
	um die Genauigkeit der Klassifizierung zwischen den beiden Kategorien zu überprüfen. 
</p>
<h4>Schwierigkeiten</h4>
<p>Während des Trainierens der Teachable Machine traten wiederholt Schwierigkeiten auf, da die Testbilder oft nicht korrekt erkannt wurden. 
	Dieses Problem ist ein typisches Hindernis beim Arbeiten mit Künstlicher Intelligenz, da der Lernprozess der Maschine nicht vollständig transparent ist 
	und es daher schwierig ist, die Ursachen für Fehlkategorisierungen zu identifizieren. Um herauszufinden, welche Faktoren zu falschen Entscheidungen führten, wurden verschiedene Experimente durchgeführt. 
	Dabei wurden der Einfluss von Farbbildern im Vergleich zu Schwarz-Weiß-Bildern, der Anteil an Weißraum sowie der Grad des Realismus in den Zeichnungen untersucht. 
	Zusätzlich wurde die Menge und Qualität der Trainingsdaten variiert. Schließlich konnte durch diese Optimierungen ein Modell entwickelt werden, das alle Testbilder eindeutig korrekt klassifizierte.

</p>

<h4>Darstellung</h4>
<p> Das Projekt wurde in Form einer interaktiven Webseite entwickelt, 
	auf der die Besuchenden durch ein Quiz selbstständig zwischen Fotografie und Zeichnung differenzieren können. 
	Besonderes wichtig ist ihre interaktive Komponente, die Nutzer dazu anregen soll ihre Wahrnehmung zu schärfen 
	und die dargestellten Bilder aufmerksam zu betrachten. 
	Im Rahmen des Quiz werden die Bilder in zufälliger Reihenfolge präsentiert, wobei die Nutzer die Aufgabe haben, 
	zwischen Foto und Zeichnung zu unterscheiden. 
	Nach der Auswahl einer Antwort wird unmittelbar die korrekte Lösung angezeigt. 
	Das Design der Webseite ist bewusst minimalistisch gehalten, um die Fokussierung auf die Bilder zu unterstützen.
</p>
<h4>Bildrechte</h4>
<p>Bei der Auswahl der Bilder, wurde leider nicht auf Bildrechte geachtet, daher kann die Seite nicht veröffentlicht werden. 
	In zukünftigen Projekten sollte darauf geachtet werden, nur Bilder zu verwenden, für die die entsprechenden Nutzungsrechte vorhanden sind.
</p>
<h4>Weiterentwicklung</h4>
<p>
	Eine mögliche Erweiterung des Projekts würde eine vergrößerte Auswahl an Bildern umfassen. 
	Zudem wäre es spannender, eine feste Anzahl an Bildern festzulegen, die erraten werden muss. 
	Im Anschluss könnte dann der erreichte Punktestand angezeigt werden, dies würde den Nutzern ermöglichen, ihre Ergebnisse mit denen von Freunden zu vergleichen. 
	Zukünftig wäre es auch interessant, das Spiel als mobile Anwendung zu entwickeln, 
	um die Möglichkeit zu bieten, online gegen Freunde anzutreten. 
	Für eine solche App würde ein ansprechenderes und spielerisch motivierendes Design besser passen.
</p>
<h4>Mögliche Anwendungen</h4>
<p>
    In einer weiterentwickelten Form könnte diese Art von Teachable Machine verwendet werden, 
	um zwischen KI-generierten Bildern und Fotografien zu differenzieren. 
	In den durchgeführten Versuchen zeigte sich, dass die Unterscheidung zwischen KI-generierten Bildern und realen Fotografien 
	oft fehleranfällig war, in einigen Fällen kam es aber bereits zu zufriedenstellenden Ergebnissen.</p>

<h4>Fazit</h4>
<p> Durch dieses Projekt ist mir noch einmal mehr klar geworden, das KI viel mehr ist als ein Sprachmodell.
	Ich habe gelernt, wie eine KI trainiert werden kann und dass das nicht immer einfach ist, 
	sondern viel Geduld und Experimentieren benötigt, um ein gutes Ergebnis zu erzielen. 
	Mir ist zudem klargeworden, wie schwierig es ist mit Bildern zu arbeiten und wie wichtig es ist auf die Bildrechte zu achten. 
	Ich habe gelernt, wie man interaktive Seiten aufbauen kann und eine Idee bekommen wie man Spiele entwickeln könnte.


</p>

</main>

    
	<footer class="footer">
		<p>Anne Fiedler | Grundlagen der digitalen Kommunikation | 2. Semester 2024 | Bei Fabian Morón Zirfas</p>


	<script src="index.js"></script>
    
</body>
</html>